{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "</center>\n",
    "Авторы материала: аспирант Мехмата МГУ Евгений Колмаков, программист-исследователь Mail.ru Group Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Домашнее задание № 3. Опциональная часть \n",
    "## <center> Реализация алгоритма построения дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем заранее `random_state` (a.k.a. random seed). Это должно повысить вероятность полной воспроизводимости результатов, впрочем, замечено, что тем не менее небольшие флуктуации возможны (например, качества прогнозов дерева, которое мы сейчас вырастим) в случае разных ОС."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Необходимо реализовать класс `DecisionTree`**\n",
    "\n",
    "**Спецификация:**\n",
    "- класс наследуется от `sklearn.BaseEstimator`;\n",
    "- конструктор содержит следующие параметры: \n",
    "    `max_depth` - максимальная глубина дерева (по умолчанию - `numpy.inf`); \n",
    "    `min_samples_split` - минимальное число объектов в вершине, при котором происходит её разбиение (по умолчанию - 2); \n",
    "    `criterion` - критерий разбиения (для классификации - 'gini' или 'entropy', для регрессии - 'variance' или 'mad_median'; \n",
    "    по умолчанию - 'gini');\n",
    "    \n",
    "    Функционал, значение которого максимизируется для поиска оптимального разбиения в данной вершине имеет вид\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$\n",
    "    где $X$ - выборка, находящаяся в текущей вершине, $X_l$ и $X_r$ - разбиение выборки $X$ на две части \n",
    "    по предикату $[x_j < t]$, а $F(X)$ -критерий разбиения.\n",
    "    \n",
    "    Для классификации: пусть $p_i$ - доля объектов $i$-го класса в выборке $X$.\n",
    "    \n",
    "    'gini': Неопределенность Джини $F(X) = 1 -\\sum_{i = 1}^K p_i^2$.\n",
    "    \n",
    "    'entropy': Энтропия $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$.\n",
    "    \n",
    "    Для регрессии: $y_j = y(x_j)$ - ответ на объекте $x_j$, $y = (y_1, \\dots, y_{|X|})$ - вектор ответов.\n",
    "    \n",
    "    'variance': Дисперсия (среднее квадратичное отклонение от среднего) $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j - \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2$\n",
    "    \n",
    "    'mad_median': Среднее отклонение от медианы $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}|y_j - \\mathrm{med}(y)|$\n",
    "    \n",
    "- класс имеет методы `fit`, `predict` и `predict_proba`;\n",
    "- метод `fit` принимает матрицу объектов `X` и вектор ответов `y` (объекты `numpy.ndarray`) и возвращает экземпляр класса\n",
    "    `DecisionTree`, представляющий собой решающее дерево, обученное по выборке `(X, y)` с учётом заданных в конструкторе параметров; \n",
    "- метод `predict_proba` принимает матрицу объектов `X` и возвращает матрицу `P` размера `X.shape[0] x K`, где `K` - число классов, такую что $p_{ij}$ есть вероятность принадлежности объекта, заданного $i$-ой строкой матрицы X к классу $j \\in \\{1, \\dots, K\\}$.\n",
    "- метод `predict` принимает матрицу объектов и возвращает вектор предсказанных ответов; в случае классификации - это \n",
    "    наиболее многочисленный класс в листе, в который попал объект, а в случае регрессии - среднее значение ответов по \n",
    "    всем объектам этого листа;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y): \n",
    "    s = 0\n",
    "    for i in set(y):\n",
    "        s += -sum(y == i) / len(y) * np.log2(sum(y == i) / len(y))\n",
    "    return s\n",
    "\n",
    "def gini(y):\n",
    "    s = 0\n",
    "    for i in set(y):  \n",
    "        s += 1 - (sum(y == i) / len(y)) ** 2\n",
    "    return s\n",
    "\n",
    "def variance(y):\n",
    "    return 1 / len(y) * sum((y - 1 / len(y) * sum(y)) ** 2)\n",
    "\n",
    "\n",
    "def mad_median(y):\n",
    "    return 1 / len(y) * sum(y - np.median(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Энтропия, если на вход подается матрица данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy1(Y2):\n",
    "    Y2 = np.hstack((Y2,np.full(fill_value='',shape=(Y2.shape[0],1))))\n",
    "    P = np.zeros((Y2.shape[0],np.unique(Y2[Y2 != '']).shape[0]))\n",
    "    for i in range(np.unique(Y2[Y2 != '']).shape[0]):\n",
    "        P[:,i] = (Y2 == np.unique(Y2[Y2 != ''])[i]).sum(axis=1) / (Y2 != '').sum(axis=1)\n",
    "\n",
    "    S = P * np.log2(P)\n",
    "    S[np.isnan(S)] = 0\n",
    "    S = - S.sum(axis = 1)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, \n",
    "                 criterion='gini', debug=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.debug = debug\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_filtered = X.T\n",
    "        \n",
    "        tree = []\n",
    "        \n",
    "        depth = 0\n",
    "        y_unique = np.unique(y)\n",
    "\n",
    "        if (max_depth + 1) >= len(y_unique):\n",
    "            length = max_depth + 1\n",
    "        else:\n",
    "            length = len(y_unique)\n",
    "\n",
    "\n",
    "        rules = [None] * length\n",
    "        \n",
    "        \n",
    "        def build(X_filtered, y, depth, rules):\n",
    "\n",
    "            if depth <= self.max_depth:\n",
    "\n",
    "                if (len(set(y)) == 1):\n",
    "                    #заполняем лист\n",
    "                    prob = np.zeros((1,length))[0]\n",
    "                    prob[np.where(y_unique == y[0])] =100\n",
    "                    #prob[:,y[0]] = 100\n",
    "\n",
    "                    tree.append([pd.DataFrame({\n",
    "                        \"depth\": depth,\n",
    "                        \"samples\": len(y),\n",
    "                        \"value\":[None] * length,\n",
    "                        \"class\": y[0],\n",
    "                        \"probability\": prob.tolist(),\n",
    "                        \"rules\": rules\n",
    "\n",
    "                        })])\n",
    "                else:    \n",
    "\n",
    "                    X_unique = np.full(\n",
    "                        (X_filtered.shape[0],\n",
    "                         len(np.unique(X_filtered))), \n",
    "                        None\n",
    "                        )\n",
    "\n",
    "                    for i in range((X_unique).shape[0]):  \n",
    "                        X_unique[i,:len(np.unique(X_filtered[i]))]\\\n",
    "                            = np.unique(X_filtered[i]) \n",
    "\n",
    "                    Y0 = y.reshape(1,len(y))\n",
    "                    #######\n",
    "                    if self.criterion == 'entropy1':\n",
    "                        S0 = entropy1(Y0)\n",
    "                    Y = np.full(fill_value=y,shape=X_filtered.shape)\n",
    "                    IG = np.zeros((X_unique.shape))\n",
    "                    for i in range(X_unique.shape[1]):\n",
    "                        X_unique_i = X_unique[:,i].reshape(X_filtered.shape[0],1)\n",
    "                        X_unique_i[X_unique_i == None] = 0\n",
    "\n",
    "                        mask = X_filtered - X_unique_i\n",
    "\n",
    "                        mask_right = mask.copy()\n",
    "                        mask_right[mask_right > 0] = ''\n",
    "                        mask_right[mask_right != ''] = True\n",
    "                        Y_right = (Y * mask_right)\n",
    "                        #####\n",
    "                        if self.criterion == 'entropy1':\n",
    "                            S_right = entropy1(Y_right)\n",
    "                        mask_right[mask_right == ''] = 0\n",
    "                        k_right = mask_right.sum(axis=1) / len(y)\n",
    "\n",
    "                        mask_left = mask.copy()\n",
    "                        mask_left[mask_left <= 0] = ''\n",
    "                        mask_left[mask_left != ''] = True\n",
    "                        Y_left = (Y * mask_left)\n",
    "                        #####\n",
    "                        if self.criterion == 'entropy1':\n",
    "                            S_left = entropy1(Y_left)\n",
    "                        mask_left[mask_left == ''] = 0\n",
    "                        k_left = mask_left.sum(axis=1) / len(y)\n",
    "\n",
    "                        IG[:,i] = S0 - k_right * S_right - k_left * S_left\n",
    "\n",
    "                    X_unique_mask = X_unique.copy()\n",
    "                    X_unique_mask[X_unique == None] = -0.1\n",
    "                    X_unique_mask[X_unique != None] = 1\n",
    "\n",
    "                    IG = IG * X_unique_mask\n",
    "\n",
    "                    i = np.where(IG == IG.max())[0][0]\n",
    "                    j = np.where(IG == IG.max())[1][0]\n",
    "\n",
    "                    y_left = y[X_filtered[i] <= X_unique[i][j]]\n",
    "                    y_right = y[X_filtered[i] > X_unique[i][j]]\n",
    "                    X_filtered_left = X_filtered[:,X_filtered[i] <= X_unique[i][j]]\n",
    "                    X_filtered_right = X_filtered[:,X_filtered[i] > X_unique[i][j]]\n",
    "                    #заполнить ветку\n",
    "\n",
    "                    df_class = pd.DataFrame(y,columns = {'class'}).groupby('class').size()\\\n",
    "                    .reset_index()\n",
    "                    df_class.columns = ['class', 'count']\n",
    "                    cl = df_class[df_class['count'] == df_class['count'].max()]['class']\n",
    "                    df_class['count'] = df_class['count']/len(y) \n",
    "\n",
    "                    prob = np.zeros((1,length))[0]\n",
    "                    for k in range(len(np.unique(y))):\n",
    "                        prob[np.where(y_unique == np.unique(y)[k])] = np.array(df_class[df_class['class'] == np.unique(y)[k]]['count']) *100\n",
    "\n",
    "                    rules_left = rules.copy()\n",
    "                    rules_right = rules.copy()\n",
    "                    rules_left[depth] = ['X_filtered[',i,']','<=', X_unique[i][j] ]\n",
    "                    rules_right[depth] = ['X_filtered[',i,']','>', X_unique[i][j] ]\n",
    "\n",
    "\n",
    "                    tree.append([pd.DataFrame({\n",
    "                        \"depth\":depth,\n",
    "                        \"samples\": len(y),\n",
    "                        \"value\":[len(y_left), len(y_right)] + [None] * (length - 2),\n",
    "                        \"class\": np.array(cl)[0],\n",
    "                        \"probability\": prob.tolist(),\n",
    "                        \"rules\": rules_left\n",
    "                         })])\n",
    "\n",
    "                    depth += 1\n",
    "                    build(X_filtered_left, y_left, depth, rules_left)\n",
    "                    build(X_filtered_right, y_right, depth, rules_right)\n",
    "\n",
    "\n",
    "            return tree\n",
    "        self.tree = build(X_filtered, y, depth, rules)\n",
    "        \n",
    "        return(self.tree)\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \n",
    "        leaf = []\n",
    "        for i in range(len(self.tree)):\n",
    "            if (self.tree[i][0]['depth'][0] == max_depth) or (sum(self.tree[i][0]['value'] >= 0) == 0):\n",
    "                leaf.append(self.tree[i][0])\n",
    "        \n",
    "        print(leaf)\n",
    "        X_filtered = X.T\n",
    "        \n",
    "        #predict\n",
    "        def predict_fn(X_filtered, leaf):\n",
    "            class_curent_matrix = np.zeros((X_filtered.shape[1],1))\n",
    "            for c in range(X_filtered.shape[1]):\n",
    " \n",
    "                i = 0\n",
    "                class_curent = 0\n",
    "                samples = 0\n",
    "                while (i < len(leaf)):\n",
    "\n",
    "                    for j in range(leaf[i]['depth'][0]+1):\n",
    "\n",
    "                        find_classes = False\n",
    "\n",
    "                        if leaf[i]['rules'][0][3] == '<=':\n",
    "                            find_classes = (X_filtered[leaf[i]['rules'][j][1],c] <= leaf[i]['rules'][j][4]) or find_classes\n",
    "                        else:\n",
    "                            find_classes = (X_filtered[leaf[i]['rules'][j][1],c] > leaf[i]['rules'][j][4]) or find_classes\n",
    "\n",
    "                        if find_classes:\n",
    "                            if leaf[i]['samples'][0] >  samples:\n",
    "                                samples = leaf[i]['samples'][0]\n",
    "                                class_curent = leaf[i]['class'][0]\n",
    "                        i += 1\n",
    "                class_curent_matrix[c,:] = class_curent\n",
    "            return class_curent_matrix  \n",
    "        \n",
    "        self.predict_matrix = predict_fn(X_filtered, leaf)\n",
    "        \n",
    "        return(self.predict_matrix)\n",
    "\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        #predict proba\n",
    "        print(self.max_depth)\n",
    "        \n",
    "        leaf = []\n",
    "        for i in range(len(self.tree)):\n",
    "            if (self.tree[i][0]['depth'][0] == max_depth) or (sum(self.tree[i][0]['value'] >= 0) == 0):\n",
    "                leaf.append(self.tree[i][0])\n",
    "        \n",
    "        X_filtered = X.T\n",
    "        \n",
    "        def predict_proba_fn(X_filtered, leaf):\n",
    "            prob_curent_matrix = np.zeros((X_filtered.shape[1],len(y_unique)))\n",
    "            for c in range(X_filtered.shape[0]):\n",
    "                #find_classes = False\n",
    "                i = 0\n",
    "                prob_curent = 0\n",
    "                \n",
    "                while (i < len(leaf)):\n",
    "                    \n",
    "                    samples = 0\n",
    "\n",
    "                    for j in range(leaf[i]['depth'][0]+1):\n",
    "\n",
    "                        find_classes = False\n",
    "                        \n",
    "                        #print(leaf[i])\n",
    "                        \n",
    "\n",
    "                        if leaf[i]['rules'][0][3] == '<=':\n",
    "                            find_classes = (X_filtered[leaf[i]['rules'][j][1],c] <= leaf[i]['rules'][j][4]) or find_classes\n",
    "                        else:\n",
    "                            find_classes = (X_filtered[leaf[i]['rules'][j][1],c] > leaf[i]['rules'][j][4]) or find_classes\n",
    "\n",
    "                        if find_classes:\n",
    "                            if leaf[i]['samples'][0] >  samples:\n",
    "                                samples = leaf[i]['samples'][0]\n",
    "                                prob_curent = leaf[i]['probability']\n",
    "                        i += 1\n",
    "                prob_curent_matrix[c,:] =prob_curent\n",
    "            return prob_curent_matrix   \n",
    "        self.prob_matrix = predict_proba_fn(X_filtered, leaf)\n",
    "        return(self.prob_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTree(max_depth=3, criterion='entropy1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log2\n",
      "  import sys\n",
      "C:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in multiply\n",
      "  import sys\n",
      "C:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[   depth  samples   value  class  probability                          rules\n",
       "  0      0     1437   419.0      6    10.020877  [X_filtered[, 21, ], <=, 1.0]\n",
       "  1      0     1437  1018.0      6    10.299235                           None\n",
       "  2      0     1437     NaN      6     9.951287                           None\n",
       "  3      0     1437     NaN      6    10.090466                           None\n",
       "  4      0     1437     NaN      6     9.812109                           None\n",
       "  5      0     1437     NaN      6     9.812109                           None\n",
       "  6      0     1437     NaN      6    10.368824                           None\n",
       "  7      0     1437     NaN      6    10.299235                           None\n",
       "  8      0     1437     NaN      6     9.603340                           None\n",
       "  9      0     1437     NaN      6     9.742519                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      1      419  218.0      6     0.238663  [X_filtered[, 21, ], <=, 1.0]\n",
       "  1      1      419  201.0      6     9.785203  [X_filtered[, 42, ], <=, 8.0]\n",
       "  2      1      419    NaN      6    10.978520                           None\n",
       "  3      1      419    NaN      6     2.386635                           None\n",
       "  4      1      419    NaN      6     9.069212                           None\n",
       "  5      1      419    NaN      6    30.310263                           None\n",
       "  6      1      419    NaN      6    35.083532                           None\n",
       "  7      1      419    NaN      6     1.431981                           None\n",
       "  8      1      419    NaN      6     0.715990                           None\n",
       "  9      1      419    NaN      6     0.000000                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      2      218   94.0      5     0.000000  [X_filtered[, 21, ], <=, 1.0]\n",
       "  1      2      218  124.0      5    15.596330  [X_filtered[, 42, ], <=, 8.0]\n",
       "  2      2      218    NaN      5    15.137615   [X_filtered[, 5, ], <=, 1.0]\n",
       "  3      2      218    NaN      5     4.587156                           None\n",
       "  4      2      218    NaN      5     4.587156                           None\n",
       "  5      2      218    NaN      5    55.045872                           None\n",
       "  6      2      218    NaN      5     1.376147                           None\n",
       "  7      2      218    NaN      5     2.293578                           None\n",
       "  8      2      218    NaN      5     1.376147                           None\n",
       "  9      2      218    NaN      5     0.000000                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      3       94   70.0      1     0.000000  [X_filtered[, 21, ], <=, 1.0]\n",
       "  1      3       94   24.0      1    36.170213  [X_filtered[, 42, ], <=, 8.0]\n",
       "  2      3       94    NaN      1    35.106383   [X_filtered[, 5, ], <=, 1.0]\n",
       "  3      3       94    NaN      1     9.574468  [X_filtered[, 38, ], <=, 0.0]\n",
       "  4      3       94    NaN      1     6.382979                           None\n",
       "  5      3       94    NaN      1     3.191489                           None\n",
       "  6      3       94    NaN      1     3.191489                           None\n",
       "  7      3       94    NaN      1     4.255319                           None\n",
       "  8      3       94    NaN      1     2.127660                           None\n",
       "  9      3       94    NaN      1     0.000000                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      3      124    6.0      5     0.000000  [X_filtered[, 21, ], <=, 1.0]\n",
       "  1      3      124  118.0      5     0.000000  [X_filtered[, 42, ], <=, 8.0]\n",
       "  2      3      124    NaN      5     0.000000    [X_filtered[, 5, ], >, 1.0]\n",
       "  3      3      124    NaN      5     0.806452   [X_filtered[, 2, ], <=, 0.0]\n",
       "  4      3      124    NaN      5     3.225806                           None\n",
       "  5      3      124    NaN      5    94.354839                           None\n",
       "  6      3      124    NaN      5     0.000000                           None\n",
       "  7      3      124    NaN      5     0.806452                           None\n",
       "  8      3      124    NaN      5     0.806452                           None\n",
       "  9      3      124    NaN      5     0.000000                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      2      201   50.0      6     0.497512  [X_filtered[, 21, ], <=, 1.0]\n",
       "  1      2      201  151.0      6     3.482587   [X_filtered[, 42, ], >, 8.0]\n",
       "  2      2      201    NaN      6     6.467662  [X_filtered[, 54, ], <=, 1.0]\n",
       "  3      2      201    NaN      6     0.000000                           None\n",
       "  4      2      201    NaN      6    13.930348                           None\n",
       "  5      2      201    NaN      6     3.482587                           None\n",
       "  6      2      201    NaN      6    71.641791                           None\n",
       "  7      2      201    NaN      6     0.497512                           None\n",
       "  8      2      201    NaN      6     0.000000                           None\n",
       "  9      2      201    NaN      6     0.000000                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      3       50   30.0      4          2.0  [X_filtered[, 21, ], <=, 1.0]\n",
       "  1      3       50   20.0      4         14.0   [X_filtered[, 42, ], >, 8.0]\n",
       "  2      3       50    NaN      4          2.0  [X_filtered[, 54, ], <=, 1.0]\n",
       "  3      3       50    NaN      4          0.0   [X_filtered[, 2, ], <=, 1.0]\n",
       "  4      3       50    NaN      4         56.0                           None\n",
       "  5      3       50    NaN      4         14.0                           None\n",
       "  6      3       50    NaN      4         10.0                           None\n",
       "  7      3       50    NaN      4          2.0                           None\n",
       "  8      3       50    NaN      4          0.0                           None\n",
       "  9      3       50    NaN      4          0.0                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      3      151  140.0      6      0.00000  [X_filtered[, 21, ], <=, 1.0]\n",
       "  1      3      151   11.0      6      0.00000   [X_filtered[, 42, ], >, 8.0]\n",
       "  2      3      151    NaN      6      7.94702   [X_filtered[, 54, ], >, 1.0]\n",
       "  3      3      151    NaN      6      0.00000   [X_filtered[, 9, ], <=, 1.0]\n",
       "  4      3      151    NaN      6      0.00000                           None\n",
       "  5      3      151    NaN      6      0.00000                           None\n",
       "  6      3      151    NaN      6     92.05298                           None\n",
       "  7      3      151    NaN      6      0.00000                           None\n",
       "  8      3      151    NaN      6      0.00000                           None\n",
       "  9      3      151    NaN      6      0.00000                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      1     1018  244.0      0    14.047151   [X_filtered[, 21, ], >, 1.0]\n",
       "  1      1     1018  774.0      0    10.510806  [X_filtered[, 36, ], <=, 3.0]\n",
       "  2      1     1018    NaN      0     9.528487                           None\n",
       "  3      1     1018    NaN      0    13.261297                           None\n",
       "  4      1     1018    NaN      0    10.117878                           None\n",
       "  5      1     1018    NaN      0     1.375246                           None\n",
       "  6      1     1018    NaN      0     0.196464                           None\n",
       "  7      1     1018    NaN      0    13.948919                           None\n",
       "  8      1     1018    NaN      0    13.261297                           None\n",
       "  9      1     1018    NaN      0    13.752456                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      2      244  146.0      0    58.606557   [X_filtered[, 21, ], >, 1.0]\n",
       "  1      2      244   98.0      0     0.819672  [X_filtered[, 36, ], <=, 3.0]\n",
       "  2      2      244    NaN      0     2.459016  [X_filtered[, 28, ], <=, 2.0]\n",
       "  3      2      244    NaN      0     1.639344                           None\n",
       "  4      2      244    NaN      0     0.409836                           None\n",
       "  5      2      244    NaN      0     4.098361                           None\n",
       "  6      2      244    NaN      0     0.409836                           None\n",
       "  7      2      244    NaN      0     0.000000                           None\n",
       "  8      2      244    NaN      0     2.868852                           None\n",
       "  9      2      244    NaN      0    28.688525                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      3      146    4.0      0    96.575342   [X_filtered[, 21, ], >, 1.0]\n",
       "  1      3      146  142.0      0     0.684932  [X_filtered[, 36, ], <=, 3.0]\n",
       "  2      3      146    NaN      0     2.054795  [X_filtered[, 28, ], <=, 2.0]\n",
       "  3      3      146    NaN      0     0.000000  [X_filtered[, 34, ], <=, 0.0]\n",
       "  4      3      146    NaN      0     0.684932                           None\n",
       "  5      3      146    NaN      0     0.000000                           None\n",
       "  6      3      146    NaN      0     0.000000                           None\n",
       "  7      3      146    NaN      0     0.000000                           None\n",
       "  8      3      146    NaN      0     0.000000                           None\n",
       "  9      3      146    NaN      0     0.000000                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      3       98   85.0      9     2.040816   [X_filtered[, 21, ], >, 1.0]\n",
       "  1      3       98   13.0      9     1.020408  [X_filtered[, 36, ], <=, 3.0]\n",
       "  2      3       98    NaN      9     3.061224   [X_filtered[, 28, ], >, 2.0]\n",
       "  3      3       98    NaN      9     4.081633  [X_filtered[, 43, ], <=, 5.0]\n",
       "  4      3       98    NaN      9     0.000000                           None\n",
       "  5      3       98    NaN      9    10.204082                           None\n",
       "  6      3       98    NaN      9     1.020408                           None\n",
       "  7      3       98    NaN      9     0.000000                           None\n",
       "  8      3       98    NaN      9     7.142857                           None\n",
       "  9      3       98    NaN      9    71.428571                           None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      2      774  255.0      7     0.000000   [X_filtered[, 21, ], >, 1.0]\n",
       "  1      2      774  519.0      7    13.565891   [X_filtered[, 36, ], >, 3.0]\n",
       "  2      2      774    NaN      7    11.757106  [X_filtered[, 61, ], <=, 0.0]\n",
       "  3      2      774    NaN      7    16.925065                           None\n",
       "  4      2      774    NaN      7    13.178295                           None\n",
       "  5      2      774    NaN      7     0.516796                           None\n",
       "  6      2      774    NaN      7     0.129199                           None\n",
       "  7      2      774    NaN      7    18.346253                           None\n",
       "  8      2      774    NaN      7    16.537468                           None\n",
       "  9      2      774    NaN      7     9.043928                           None],\n",
       " [   depth  samples  value  class  probability                           rules\n",
       "  0      3      255  165.0      7     0.000000    [X_filtered[, 21, ], >, 1.0]\n",
       "  1      3      255   90.0      7     4.705882    [X_filtered[, 36, ], >, 3.0]\n",
       "  2      3      255    NaN      7     1.176471   [X_filtered[, 61, ], <=, 0.0]\n",
       "  3      3      255    NaN      7     2.745098  [X_filtered[, 26, ], <=, 12.0]\n",
       "  4      3      255    NaN      7    25.098039                            None\n",
       "  5      3      255    NaN      7     1.176471                            None\n",
       "  6      3      255    NaN      7     0.000000                            None\n",
       "  7      3      255    NaN      7    54.901961                            None\n",
       "  8      3      255    NaN      7     5.098039                            None\n",
       "  9      3      255    NaN      7     5.098039                            None],\n",
       " [   depth  samples  value  class  probability                          rules\n",
       "  0      3      519  234.0      3     0.000000   [X_filtered[, 21, ], >, 1.0]\n",
       "  1      3      519  285.0      3    17.919075   [X_filtered[, 36, ], >, 3.0]\n",
       "  2      3      519    NaN      3    16.955684   [X_filtered[, 61, ], >, 0.0]\n",
       "  3      3      519    NaN      3    23.892100  [X_filtered[, 43, ], <=, 3.0]\n",
       "  4      3      519    NaN      3     7.321773                           None\n",
       "  5      3      519    NaN      3     0.192678                           None\n",
       "  6      3      519    NaN      3     0.192678                           None\n",
       "  7      3      519    NaN      3     0.385356                           None\n",
       "  8      3      519    NaN      3    22.157996                           None\n",
       "  9      3      519    NaN      3    10.982659                           None]]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование реализованного алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `load_digits` загрузите датасет `digits`. Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=17`. Попробуйте обучить неглубокие решающие деревья и убедитесь, что критерии gini и entropy дают разные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью 5-кратной кросс-валидации (`GridSearchCV`) подберите оптимальное значение параметров `max_depth` и `criterion`. Для параметра `max_depth` используйте диапазон значений - range(3, 11), а для criterion - {'gini', 'entropy'}. Критерий качества `scoring`='accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики средних значений критерия качества `accuracy` для критериев `gini` и `entropy` в зависимости от `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выберите верные утверждения:**\n",
    "1. Оптимальное значение `max_depth` для каждого критерия достигается на отрезке [4, 9].\n",
    "2. На отрезке [3, 10] построенные графики не пересекаются.\n",
    "3. На отрезке [3, 10] построенные графики пересекаются ровно один раз.\n",
    "4. Наилучшее качество при `max_depth` на интервале [3, 10] достигается при использовании критерия `gini`.\n",
    "5. Хотя бы для одного из критериев значение accuracy строго возрастает с ростом значения `max_depth` на интервале [3, 10]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чему равны найденные оптимальные значения параметров max_depth и criterion?**\n",
    "1. max_depth = 7, criterion = 'gini';\n",
    "2. max_depth = 7, criterion = 'entropy';\n",
    "3. max_depth = 10, criterion = 'entropy';\n",
    "4. max_depth = 10, criterion = 'gini';\n",
    "5. max_depth = 9, criterion = 'entropy';\n",
    "6. max_depth = 9, criterion = 'gini';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя найденные оптимальные значения max_depth и criterion, обучите решающее дерево на X_train, y_train и вычислите вероятности принадлежности к классам для X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полученной матрицы вычислите усредненные по всем объектам из `X_test` значения вероятностей принадлежности к классам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** Чему примерно равна максимальная вероятность в полученном векторе?\n",
    "1. 0.127\n",
    "2. 0.118\n",
    "3. 1.0\n",
    "4. 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `load_boston` загрузите датасет `boston`. Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=17`. Попробуйте обучить неглубокие регрессионные деревья и убедитесь, что критерии `variance` и `mad_median` дают разные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью 5-кратной кросс-валидации подберите оптимальное значение параметров `max_depth` и `criterion`. Для параметра `max_depth` используйте диапазон значений - `range(2, 9)`, а для `criterion` - {'variance', 'mad_median'}. Критерий качества `scoring`='neg_mean_squared_error'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики средних значений критерия качества `neg_mean_squared_error` для критериев `variance` и `mad_median` в зависимости от `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выберите верные утверждения:**\n",
    "1. На отрезке [2, 8] построенные графики не пересекаются.\n",
    "2. На отрезке [2, 8] построенные графики пересекаются ровно один раз.\n",
    "3. Оптимальное значение `max_depth` для каждого из критериев достигается на границе отрезка [2, 8].\n",
    "4. Наилучшее качество при `max_depth` из [2, 8] достигается при использовании критерия `mad_median`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чему равны найденные оптимальные значения параметров `max_depth` и `criterion`?**\n",
    "1. max_depth = 9, criterion = 'variance';\n",
    "2. max_depth = 5, criterion = 'mad_median';\n",
    "3. max_depth = 4, criterion = 'variance';\n",
    "4. max_depth = 2, criterion = 'mad_median';\n",
    "5. max_depth = 4, criterion = 'mad_median';\n",
    "6. max_depth = 5, criterion = 'variance';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
